{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMtTRuqVk5mKxNvXdQ5kUgo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4aM-GOVKZCB5","executionInfo":{"status":"ok","timestamp":1700210332577,"user_tz":-330,"elapsed":731,"user":{"displayName":"Swetha Priya Desireddy","userId":"17914462415889962534"}},"outputId":"4f5938aa-9cd6-4a70-bd3d-3b7d19e9694c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Available combinations :  [(0.1, 100), (0.1, 200), (0.1, 300), (0.1, 400), (0.1, 500), (0.2, 100), (0.2, 200), (0.2, 300), (0.2, 400), (0.2, 500), (0.3, 100), (0.3, 200), (0.3, 300), (0.3, 400), (0.3, 500), (0.4, 100), (0.4, 200), (0.4, 300), (0.4, 400), (0.4, 500), (0.5, 100), (0.5, 200), (0.5, 300), (0.5, 400), (0.5, 500), (0.01, 100), (0.01, 200), (0.01, 300), (0.01, 400), (0.01, 500), (0.02, 100), (0.02, 200), (0.02, 300), (0.02, 400), (0.02, 500), (0.03, 100), (0.03, 200), (0.03, 300), (0.03, 400), (0.03, 500), (0.04, 100), (0.04, 200), (0.04, 300), (0.04, 400), (0.04, 500), (0.05, 100), (0.05, 200), (0.05, 300), (0.05, 400), (0.05, 500)]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-10-6b32096b4e6c>:31: RuntimeWarning: overflow encountered in exp\n","  A = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) )\n","<ipython-input-10-6b32096b4e6c>:46: RuntimeWarning: overflow encountered in exp\n","  Z = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )\n"]},{"output_type":"stream","name":"stdout","text":["Maximum accuracy achieved by our model through grid searching :  70.58823529411765\n"]}],"source":["# Importing libraries\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Grid Searching in Logistic Regression\n","class LogitRegression() :\n","\tdef __init__( self, learning_rate, iterations ) :\n","\t\tself.learning_rate = learning_rate\n","\t\tself.iterations = iterations\n","\n","\t# Function for model training\n","\tdef fit( self, X, Y ) :\n","\t\t# no_of_training_examples, no_of_features\n","\t\tself.m, self.n = X.shape\n","\n","\t\t# weight initialization\n","\t\tself.W = np.zeros( self.n )\n","\t\tself.b = 0\n","\t\tself.X = X\n","\t\tself.Y = Y\n","\n","\t\t# gradient descent learning\n","\t\tfor i in range( self.iterations ) :\n","\t\t\tself.update_weights()\n","\t\treturn self\n","\n","\t# Helper function to update weights in gradient descent\n","\tdef update_weights( self ) :\n","\t\tA = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) )\n","\n","\t\t# calculate gradients\n","\t\ttmp = ( A - self.Y.T )\n","\t\ttmp = np.reshape( tmp, self.m )\n","\t\tdW = np.dot( self.X.T, tmp ) / self.m\n","\t\tdb = np.sum( tmp ) / self.m\n","\n","\t\t# update weights\n","\t\tself.W = self.W - self.learning_rate * dW\n","\t\tself.b = self.b - self.learning_rate * db\n","\t\treturn self\n","\n","\t# Hypothetical function h( x )\n","\tdef predict( self, X ) :\n","\t\tZ = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )\n","\t\tY = np.where( Z > 0.5, 1, 0 )\n","\t\treturn Y\n","\n","\n","# Driver code\n","\n","def main() :\n","\n","\t# Importing dataset\n","\tdf = pd.read_csv( \"diabetes.csv\" )\n","\tX = df.iloc[:,:-1].values\n","\tY = df.iloc[:,-1:].values\n","\n","\t# Splitting dataset into train and validation set\n","\tX_train, X_valid, Y_train, Y_valid = train_test_split(\n","\tX, Y, test_size = 1/3, random_state = 0 )\n","\n","\t# Model training\n","\tmax_accuracy = 0\n","\n","\t# learning_rate choices\n","\tlearning_rates = [ 0.1, 0.2, 0.3, 0.4, 0.5,\n","\t\t\t\t\t0.01, 0.02, 0.03, 0.04, 0.05 ]\n","\n","\t# iterations choices\n","\titerations = [ 100, 200, 300, 400, 500 ]\n","\n","\t# available combination of learning_rate and iterations\n","\n","\tparameters = []\n","\tfor i in learning_rates :\n","\t\tfor j in iterations :\n","\t\t\tparameters.append( ( i, j ) )\n","\n","\tprint(\"Available combinations : \", parameters )\n","\n","\t# Applying linear searching in list of available combination\n","\t# to achieved maximum accuracy on CV set\n","\n","\tfor k in range( len( parameters ) ) :\n","\t\tmodel = LogitRegression( learning_rate = parameters[k][0],\n","\t\t\t\t\t\t\t\titerations = parameters[k][1] )\n","\n","\t\tmodel.fit( X_train, Y_train )\n","\n","\t\t# Prediction on validation set\n","\t\tY_pred = model.predict( X_valid )\n","\n","\t\t# measure performance on validation set\n","\n","\t\tcorrectly_classified = 0\n","\n","\t\t# counter\n","\t\tcount = 0\n","\n","\t\tfor count in range( np.size( Y_pred ) ) :\n","\t\t\tif Y_valid[count] == Y_pred[count] :\n","\t\t\t\tcorrectly_classified = correctly_classified + 1\n","\n","\t\tcurr_accuracy = ( correctly_classified / count ) * 100\n","\n","\t\tif max_accuracy < curr_accuracy :\n","\t\t\tmax_accuracy = curr_accuracy\n","\n","\tprint( \"Maximum accuracy achieved by our model through grid searching : \", max_accuracy )\n","\n","if __name__ == \"__main__\" :\n","\tmain()"]}]}